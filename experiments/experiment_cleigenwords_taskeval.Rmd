---
title: "Task evaluation of Cross-Lingual Eigenwords and its related works"
date: "`r Sys.time()`"
output: html_document
---

# Preparation
```{r}
time.begin <- Sys.time()
```

If `run_cleigenwords.html` does NOT exists, render `run_cleigenwords.Rmd`.

```{r, results='hide'}
rmarkdown::render("run_cleigenwords.Rmd")
```

```{r, include=FALSE}
library(knitr)
library(RecordLinkage)
library(foreach)
library(doParallel)

source("./../src/kadingir.R", chdir = TRUE)
```

0. Preprocessing Europarl corpus (`preprocess_europarl.sh`)
1. Execute CL-Eigenwords (`experiment_cleigenwords.Rmd`)
2. Make translate table using Google Translates (Google Spreadsheet)

まず，以下のコードを実行し，CL-Eigenwords で用いた単語のリストを作成する．

```
load("res_cleigenwords.Rdata")
write(paste0(r$vocab.words[[1]], collapse = "\n"), "output_vocab_es-en_es.csv")
write(paste0(r$vocab.words[[2]], collapse = "\n"), "output_vocab_es-en_en.csv")
```

`output_vocab_es-en_??.csv` 中の単語について，Google Spreadsheet の `GOOGLETRANSLATE` 関数で対訳を生成する．

```{r, results = "asis"}
translate.table <- read.csv("translate_table_es-en_es_0121_reduced.csv", sep = ",", as.is = TRUE)
kable(head(translate.table[ , c("es","en")]))
```

```{r, message=FALSE}
load("res_cleigenwords.Rdata")

p <- r$p_head_domains
V.es <- r$V[p[1]:p[2], ]
V.en <- r$V[(p[3]+1):p[4], ]
vocab.words.es <- paste0("(es)", r$vocab.words[[1]])
vocab.words.en <- paste0("(en)", r$vocab.words[[2]])

V <- rbind(V.es, V.en)
vocab.words <- c(vocab.words.es, vocab.words.en)
```

## Execute Cross-Lingual LSA
```{r}
path.cllsa.rdata <- "res_cllsa.Rdata"

if (TRUE || !file.exists(path.cllsa.rdata)) {
  cat("Calculate CL-LSA...\n")

  sourceCpp("./../src/cllsa_core.cpp", rebuild = TRUE)
  
  res.cllsa <- CLLSA(r$corpus.concated, r$document.id.concated,
                     r$sizes.vocabulary, r$lengths.sentence,
                     dim_common_space = 400)
  
  res.cllsa$representations.word <- res.cllsa$word_representations
  save(res.cllsa, file = path.cllsa.rdata)
  
} else {
  load(path.cllsa.rdata)
}

V.cllsa <- res.cllsa$representations.word

# Check vector representations
MostSimilar(V.cllsa, vocab.words, positive = c("(en)he"), distance = "cosine", language.search = "en")
MostSimilar(V.cllsa, vocab.words, positive = c("(en)he"), distance = "cosine", language.search = "es")
```

# Evaluation
```{r}
cl <- makeCluster(12)
registerDoParallel(cl)

queries <- paste0("(es)", as.character(translate.table[ , "es"]))
n.queries <- length(queries)
answers.machinetranslate <- paste0("(en)", as.character(translate.table[ , "en"]))
topn <- 5  # P@topn
distance <- "cosine"
weight.vector <- r$svd$singular_values  # sqrt of weighting vector (ex. d(x, y):= t(x) %*% diag(weight.vector**2) %*% y)

# Search word that have minimum edit distance with `query` from `vocab.search`
search.adist <- function (query, vocab.search, topn = 1)
{
  vector.adist <- RecordLinkage::levenshteinDist(query, vocab.search)
  names(vector.adist) <- vocab.search
  
  if (topn == 1) {
    return(names(which.min(vector.adist)))
  } else {
    return(names(vector.adist[order(vector.adist)[seq(topn)]]))
  }
}


results <- foreach (i.query = seq(queries), .combine = rbind) %dopar% {
  query <- queries[i.query]
  query.nolang <- substr(query, 5, 100)  # `query` with no language identifier
  answer.collect <- tolower(answers.machinetranslate[i.query])
  answer.collect.nolang <- tolower(substr(answers.machinetranslate[i.query], 5, 100))
  answers.cleigenwords.query <- names(MostSimilar(V, vocab.words, positive=c(query), distance = distance, language.search = "en", topn = topn, weight.vector = weight.vector))
  answers.cllsa.query <- names(MostSimilar(V.cllsa, vocab.words, positive = c(query), distance = distance, language.search = "en", topn = topn))

  word.most.similar.cleigenwords <- answers.cleigenwords.query[1]
  if (is.null(word.most.similar.cleigenwords)) { word.most.similar.cleigenwords <- "" }
  
  word.most.similar.cllsa <- answers.cllsa.query[1]
  if (is.null(word.most.similar.cllsa)) { word.most.similar.cllsa <- "" }
  
  # Edit distance
  answers.adist.query <- search.adist(query.nolang, r$vocab.words[[2]], topn = 5)

  data.frame(
    queries = query,
    answer.machinetranslate = answer.collect,
    answer.cleigenwords = word.most.similar.cleigenwords,
    answer.cllsa = word.most.similar.cllsa,
    answer.adist = answers.adist.query[1],
    correct.at.n.cleigenwords = answer.collect %in% tolower(answers.cleigenwords.query),
    correct.at.n.cllsa = answer.collect %in% tolower(answers.cllsa.query),
    correct.at.n.adist = answer.collect.nolang %in% tolower(answers.adist.query)
  )
}

stopCluster(cl)
registerDoSEQ()

results$answer.adist <- paste0("(en)", results$answer.adist)
```

```{r, results = "asis"}
kable(results[1:20, ])
```

今回は，

1. Generalized Levenshtein edit distance (using `adist` function of R)
2. Cross-Lingual LSA
3. **Cross-Lingual Eigenwords** (Proposed method)

による検索の精度 (Precision\@1, Precision\@5) を表示する．

```{r}
accuracy.between <- function(col1, col2)
{
  return( mean(tolower(as.character(results[ , col1])) == tolower(as.character(results[ , col2]))) )
}

accuracy <- c(accuracy.between("answer.machinetranslate", "answer.adist"),
              accuracy.between("answer.machinetranslate", "answer.cllsa"),
              accuracy.between("answer.machinetranslate", "answer.cleigenwords"),
              mean(results[ , "correct.at.n.adist"]),
              mean(results[ , "correct.at.n.cllsa"]),
              mean(results[ , "correct.at.n.cleigenwords"]))
```

```{r, results = "asis"}
kable(
  matrix(accuracy, nrow = 3,
         dimnames = list(c("Edit distance", "CL-LSA", "CL-Eigenwords"),
                         c("P@1", paste0("P@", topn)))
         )
  )
```

# Precision\@5 for top-$n$ frequently used words
```{r}
precision <- cbind(cumsum(results[, c("correct.at.n.adist")])/seq(nrow(results)),
                   cumsum(results[, c("correct.at.n.cllsa")])/seq(nrow(results)),
                   cumsum(results[, c("correct.at.n.cleigenwords")])/seq(nrow(results)))
colnames(precision) <- c("Edit distance", "CL-LSA", "CL-Eigenwords")
col <- c("black", "red", "blue")
matplot(precision, xlab="rank", ylab=paste0("Precision@", topn), type="l", lwd = 4, lty = 1, col = col)
legend("bottomright", legend = colnames(precision), pch = 1, col = col)
```

```{r}
accuracy.partial <- function(begin){
  accuracy.at <- colMeans(results[1:1000 + begin, 6:8])
}

begin.vector <- c(0, 1000, 2000, 3000, 4000, 5000, 6000)
accuracy.fromto <- NULL
for(begin in begin.vector) {
  accuracy.fromto <- rbind(accuracy.fromto, accuracy.partial(begin))
}
row.names(accuracy.fromto) <- as.character(paste0(begin.vector + 1, ":", begin.vector + 1000))

kable(accuracy.fromto)
```

```{r}
Sys.time() - time.begin
Sys.time()
```