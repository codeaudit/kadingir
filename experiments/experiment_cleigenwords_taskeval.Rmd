---
title: "Task evaluation of Cross-Lingual Eigenwords and its related works"
author: "OSHIKIRI Takamasa"
date: "`r Sys.time()`"
output: html_document
---

提案手法である Cross-Lingual Eigenwords の評価を行う

# Preparation
```{r}
time.begin <- Sys.time()
```

```{r, include=FALSE}
rmarkdown::render("run_cleigenwords.Rmd")
```

```{r, include=FALSE}
library(knitr)
library(RecordLinkage)
source("./../src/kadingir.R", chdir = TRUE)
```

0. Preprocessing Europarl corpus (`preprocess_europarl.sh`)
1. Execute CL-Eigenwords (`experiment_cleigenwords.Rmd`)
2. Make translate table using Google Translates (Google Spreadsheet)

まず，以下のコードを実行し，CL-Eigenwords で用いた単語のリストを作成する．

```
load("res_cleigenwords.Rdata")
write(paste0(r$vocab.words[[1]], collapse = "\n"), "output_vocab_es-en_es.csv")
write(paste0(r$vocab.words[[2]], collapse = "\n"), "output_vocab_es-en_en.csv")
```

`output_vocab_es-en_??.csv` 中の単語について，Google Spreadsheet の `GOOGLETRANSLATE` 関数で対訳を生成する．

```{r, results = "asis"}
translate.table <- read.csv("translate_table_es-en_es_0121_reduced.csv", sep = ",", as.is = TRUE)
kable(head(translate.table[ , c("es","en")]))
```

```{r, message=FALSE}
load("res_cleigenwords.Rdata")

p <- r$svd$p_head_domains
V.es <- r$svd$V[p[1]:p[2], ]
V.en <- r$svd$V[(p[3]+1):p[4], ]
vocab.words.es <- paste0("(es)", r$vocab.words[[1]])
vocab.words.en <- paste0("(en)", r$vocab.words[[2]])

V <- rbind(V.es, V.en)
vocab.words <- c(vocab.words.es, vocab.words.en)
```

## Execute Cross-Lingual LSA
```{r}
path.cllsa.rdata <- "res_cllsa.Rdata"

if (!file.exists(path.cllsa.rdata)) {
  sourceCpp("./../src/cllsa_core.cpp", rebuild = TRUE)
  
  res.cllsa <- CLLSA(r$corpus.concated, r$document.id.concated,
                     r$sizes.vocabulary, r$lengths.sentence,
                     dim_common_space = 100)
  
  res.cllsa$representations.word <- res.cllsa$word_representations
  save(res.cllsa, file = path.cllsa.rdata)
  
} else {
  load(path.cllsa.rdata)
}

# Check vector representations
MostSimilar(res.cllsa$representations.word, vocab.words,
            positive = c("(en)he"), distance = "cosine", language.search = "en")
MostSimilar(res.cllsa$representations.word, vocab.words,
            positive = c("(en)he"), distance = "cosine", language.search = "es")
```

# Evaluation
```{r}
queries <- paste0("(es)", as.character(translate.table[ , "es"]))
n.queries <- length(queries)
answers.machinetranslate <- paste0("(en)", as.character(translate.table[ , "en"]))
answers.cleigenwords <- vector(mode = "character", length = n.queries)
answers.cllsa <- vector(mode = "character", length = n.queries)
answers.adist <- vector(mode = "character", length = n.queries)
correct.at.n.cleigenwords <- vector(mode = "logical", length = n.queries)
correct.at.n.cllsa <- vector(mode = "logical", length = n.queries)
correct.at.n.adist <- vector(mode = "logical", length = n.queries)
topn <- 5  # P@topn
distance <- "cosine"
weight.vector <- r$svd$singular_values

# Search word that have minimum edit distance with `query` from `vocab.search`
search.adist <- function (query, vocab.search, topn = 1)
{
  vector.adist <- levenshteinDist(query, vocab.search)
  names(vector.adist) <- vocab.search
  
  if (topn == 1) {
    return(names(which.min(vector.adist)))
  } else {
    return(names(vector.adist[order(vector.adist)[seq(topn)]]))
  }
}


for (i.query in seq(queries)) {
  query <- queries[i.query]
  query.nolang <- substr(query, 5, 100)  # `query` with no language identifier
  answer.collect <- tolower(answers.machinetranslate[i.query])
  answer.collect.nolang <- tolower(substr(answers.machinetranslate[i.query], 5, 100))
  answers.cleigenwords.query <- names(MostSimilar(V, vocab.words, positive=c(query), distance = distance, language.search = "en", topn = topn, weight.vector = weight.vector))
  answers.cllsa.query <- names(MostSimilar(res.cllsa$representations.word, vocab.words, positive = c(query), distance = distance, language.search = "en", topn = topn))

  word.most.similar.cleigenwords <- answers.cleigenwords.query[1]
  if (is.null(word.most.similar.cleigenwords)) { word.most.similar.cleigenwords <- "" }
  
  word.most.similar.cllsa <- answers.cllsa.query[1]
  if (is.null(word.most.similar.cllsa)) { word.most.similar.cllsa <- "" }
  
  # Edit distance
  answers.adist.query <- search.adist(query.nolang, r$vocab.words[[2]], topn = 5)
  
  answers.cleigenwords[i.query] <- word.most.similar.cleigenwords
  answers.cllsa[i.query] <- word.most.similar.cllsa
  correct.at.n.cleigenwords[i.query] <- answer.collect %in% tolower(answers.cleigenwords.query)
  correct.at.n.cllsa[i.query] <- answer.collect %in% tolower(answers.cllsa.query)
  correct.at.n.adist[i.query] <- answer.collect.nolang %in% tolower(answers.adist.query)
  answers.adist[i.query] <- answers.adist.query[1]
}

answers.adist <- paste0("(en)", answers.adist)

results <- data.frame(queries = queries,
                      answer.machinetranslate = answers.machinetranslate,
                      answer.cleigenwords = answers.cleigenwords,
                      answer.cllsa = answers.cllsa,
                      answer.adist = answers.adist,
                      correct.at.n.cleigenwords = correct.at.n.cleigenwords,
                      correct.at.n.cllsa = correct.at.n.cllsa,
                      correct.at.n.adist= correct.at.n.adist)
```

```{r, results = "asis"}
kable(results[1:20, ])
```

今回は，

1. Generalized Levenshtein edit distance (using `adist` function of R)
2. Cross-Lingual LSA
3. **Cross-Lingual Eigenwords** (Proposed method)

による検索の精度 (Precision\@1, Precision\@5) を表示する．

```{r}
accuracy.between <- function(col1, col2)
{
  return( mean(tolower(as.character(results[ , col1])) == tolower(as.character(results[ , col2]))) )
}

accuracy <- c(accuracy.between("answer.machinetranslate", "answer.adist"),
              accuracy.between("answer.machinetranslate", "answer.cllsa"),
              accuracy.between("answer.machinetranslate", "answer.cleigenwords"),
              mean(results[ , "correct.at.n.adist"]),
              mean(results[ , "correct.at.n.cllsa"]),
              mean(results[ , "correct.at.n.cleigenwords"]))
```

```{r, results = "asis"}
kable(
  matrix(accuracy, nrow = 3,
         dimnames = list(c("Edit distance", "CL-LSA", "CL-Eigenwords"),
                         c("P@1", paste0("P@", topn)))
         )
  )
```

# 頻出上位 $n$ 件のときの Precision\@5 のグラフ
```{r}
precision <- cbind(cumsum(results[, c("correct.at.n.adist")])/seq(nrow(results)),
                   cumsum(results[, c("correct.at.n.cllsa")])/seq(nrow(results)),
                   cumsum(results[, c("correct.at.n.cleigenwords")])/seq(nrow(results)))
colnames(precision) <- c("Edit distance", "CL-LSA", "CL-Eigenwords")
matplot(precision, pch = 1:3, xlab="rank", ylab=paste0("Precision@", topn))
legend("bottomright", legend = colnames(precision), pch = 1:3, col = 1:3)
```

```{r}
accuracy.partial <- function(begin){
  accuracy.at <- colMeans(results[1:1000 + begin, 6:8])
}

begin.vector <- c(0, 1000, 2000, 3000, 4000, 5000, 6000)
accuracy.fromto <- NULL
for(begin in begin.vector) {
  accuracy.fromto <- rbind(accuracy.fromto, accuracy.partial(begin))
}
row.names(accuracy.fromto) <- as.character(paste0(begin.vector + 1, ":", begin.vector + 1000))

kable(accuracy.fromto)
```

```{r}
Sys.time() - time.begin
Sys.time()
```