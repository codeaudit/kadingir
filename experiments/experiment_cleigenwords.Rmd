---
title: "Experiments of Cross-Lingual Eigenwords"
author: "OSHIKIRI Takamasa"
date: "2016/1/12"
output: html_document
---

提案手法である Cross-Lingual Eigenwords の評価を行う

# 事前の準備

0. データの前処理 (`preprocess_europarl.sh`)
1. CL-Eigenwords を実行 (`run_cleigenwords.R`)
2. タスクによる評価に用いる単語の対訳表を作成しておく．

まず，以下のコードを実行し，CL-Eigenwords で用いた単語のリストを作成する．

```
load("./../res_cleigenwords_es-en_phrase2.Rdata")
write(paste0(r$vocab.words[[1]], collapse = "\n"), "output_vocab_es-en_es_phrase2.csv")
write(paste0(r$vocab.words[[2]], collapse = "\n"), "output_vocab_es-en_en_phrase2.csv")
```

その後，Google Spreadsheet で `output\_vocab\_es-en_??.csv` から対訳表を作成する．

# 準備
```{r, message=FALSE}
library(knitr)
library(RecordLinkage)
source("./../src/kadingir.R", chdir = TRUE)
load("./../res_cleigenwords_20160121.Rdata")


p <- r$svd$p_head_domains
V.es <- r$svd$V[p[1]:p[2], ]
V.en <- r$svd$V[(p[3]+1):p[4], ]
vocab.words.es <- paste0("(es)", r$vocab.words[[1]])
vocab.words.en <- paste0("(en)", r$vocab.words[[2]])

V <- rbind(V.es, V.en)
vocab.words <- c(vocab.words.es, vocab.words.en)
```

## Cross-Lingual LSA を実行する
```{r}
sourceCpp("./../src/cllsa_core.cpp", rebuild = TRUE)

res.cllsa <- CLLSA(r$corpus.concated, r$document.id.concated,
                   r$sizes.vocabulary, r$lengths.sentence,
                   dim_common_space = 100)

res.cllsa$representations.word <- res.cllsa$word_representations

# Check vector representations
MostSimilar(res.cllsa$representations.word, vocab.words,
            positive = c("(en)he"), distance = "cosine", language.search = "en")
```

# 評価
Google Spreadsheet の `GOOGLETRANSLATE` 関数で生成した対訳表を読み込む．

```{r, results = "asis"}
translate.table <- read.csv("translate_table_es-en_es_reduced.csv", sep = ",", as.is = TRUE)[1:1000 + 2000, ]
kable(head(translate.table[ , c("es","en")]))
```


```{r}
queries <- paste0("(es)", as.character(translate.table[ , "es"]))
n.queries <- length(queries)
answers.machinetranslate <- paste0("(en)", as.character(translate.table[ , "en"]))
answers.cleigenwords <- vector(mode = "character", length = n.queries)
answers.cllsa <- vector(mode = "character", length = n.queries)
answers.adist <- vector(mode = "character", length = n.queries)
correct.at.n.cleigenwords <- vector(mode = "logical", length = n.queries)
correct.at.n.cllsa <- vector(mode = "logical", length = n.queries)
correct.at.n.adist <- vector(mode = "logical", length = n.queries)
topn <- 5  # P@topn
distance <- "euclid"

# Search word that have minimum edit distance with `query` from `vocab.search`
search.adist <- function (query, vocab.search, topn = 1)
{
  vector.adist <- levenshteinDist(query, vocab.search)
  names(vector.adist) <- vocab.search
  
  if (topn == 1) {
    return(names(which.min(vector.adist)))
  } else {
    return(names(vector.adist[order(vector.adist)[seq(topn)]]))
  }
}


for (i.query in seq(queries)) {
  query <- queries[i.query]
  query.nolang <- substr(query, 5, 100)  # `query` with no language identifier
  answer.collect <- tolower(answers.machinetranslate[i.query])
  answer.collect.nolang <- tolower(substr(answers.machinetranslate[i.query], 5, 100))
  answers.cleigenwords.query <- names(MostSimilar(V, vocab.words, positive=c(query), distance = distance, language.search = "en", topn = topn))
  answers.cllsa.query <- names(MostSimilar(res.cllsa$representations.word, vocab.words, positive = c(query), distance = distance, language.search = "en", topn = topn))

  word.most.similar.cleigenwords <- answers.cleigenwords.query[1]
  if (is.null(word.most.similar.cleigenwords)) { word.most.similar.cleigenwords <- "" }
  
  word.most.similar.cllsa <- answers.cllsa.query[1]
  if (is.null(word.most.similar.cllsa)) { word.most.similar.cllsa <- "" }
  
  # Edit distance
  answers.adist.query <- search.adist(query.nolang, r$vocab.words[[2]], topn = 5)
  
  answers.cleigenwords[i.query] <- word.most.similar.cleigenwords
  answers.cllsa[i.query] <- word.most.similar.cllsa
  correct.at.n.cleigenwords[i.query] <- answer.collect %in% tolower(answers.cleigenwords.query)
  correct.at.n.cllsa[i.query] <- answer.collect %in% tolower(answers.cllsa.query)
  correct.at.n.adist[i.query] <- answer.collect.nolang %in% tolower(answers.adist.query)
  answers.adist[i.query] <- answers.adist.query[1]
}

answers.adist <- paste0("(en)", answers.adist)

results <- data.frame(queries = queries,
                      answer.machinetranslate = answers.machinetranslate,
                      answer.cleigenwords = answers.cleigenwords,
                      answer.cllsa = answers.cllsa,
                      answer.adist = answers.adist,
                      correct.at.n.cleigenwords = correct.at.n.cleigenwords,
                      correct.at.n.cllsa = correct.at.n.cllsa,
                      correct.at.n.adist= correct.at.n.adist)
```

```{r, results = "asis"}
kable(results[1:20, ])
```

今回は，

1. Generalized Levenshtein edit distance (編集距離，R の `adist` 関数を使った)
2. Cross-Lingual LSA
3. **Cross-Lingual Eigenwords** (提案手法)

による検索の精度 (Precision@1, Precision@5) を表示する．

```{r}
accuracy.between <- function(col1, col2)
{
  return( mean(tolower(as.character(results[ , col1])) == tolower(as.character(results[ , col2]))) )
}

accuracy <- c(accuracy.between("answer.machinetranslate", "answer.adist"),
              accuracy.between("answer.machinetranslate", "answer.cllsa"),
              accuracy.between("answer.machinetranslate", "answer.cleigenwords"),
              mean(results[ , "correct.at.n.adist"]),
              mean(results[ , "correct.at.n.cllsa"]),
              mean(results[ , "correct.at.n.cleigenwords"]))
```

```{r, results = "asis"}
kable(
  matrix(accuracy, nrow = 3,
         dimnames = list(c("Edit distance", "CL-LSA", "CL-Eigenwords"),
                         c("P@1", paste0("P@", topn)))
         )
  )
```